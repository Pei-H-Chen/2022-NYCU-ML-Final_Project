{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression, HuberRegressor\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from scipy.stats import rankdata\n",
    "import itertools\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "num_result, num_model = 3, 5\n",
    "with open(\"models.pckl\", \"rb\") as f:\n",
    "    while True:\n",
    "        try:\n",
    "            for i in range(0, num_result):\n",
    "                tmp_model = []\n",
    "                for j in range(0, num_model):\n",
    "                    tmp_model.append(pickle.load(f))\n",
    "                models.append(tmp_model)\n",
    "        except EOFError:\n",
    "            break\n",
    "assert len(models) == 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (26570, 26), test (20775, 25)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "submission_df = pd.read_csv('sample_submission.csv')\n",
    "print(f'train {train_df.shape}, test {test_df.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_feature = train_df.columns\n",
    "featType_float = train_df.select_dtypes(float).columns\n",
    "featType_int = train_df.select_dtypes(int).columns\n",
    "featType_object = train_df.select_dtypes(object).columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode: attribute0 & 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "train_df_encode = train_df.copy()\n",
    "test_df_encode = test_df.copy()\n",
    "train_size = train_df.shape[0]\n",
    "\n",
    "encode_object = featType_object.drop(['product_code'])\n",
    "for column in encode_object:\n",
    "        merge_data = pd.concat([train_df[column], test_df[column]])\n",
    "        tmp_encode = label_encoder.fit_transform(merge_data)\n",
    "        train_df_encode[column] = tmp_encode[:train_size]\n",
    "        test_df_encode[column] = tmp_encode[train_size:]\n",
    "        \n",
    "train_df = train_df_encode\n",
    "test_df = test_df_encode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kaggle discussion -> m3_missing & m5_missing are important features\n",
    "data_t = pd.concat([train_df, test_df])\n",
    "data_t['m3_missing'] = data_t['measurement_3'].isnull().astype(np.int8)\n",
    "data_t['m5_missing'] = data_t['measurement_5'].isnull().astype(np.int8)\n",
    "\n",
    "# from kaggle discussion -> suggest to log(loading)\n",
    "data_t['loading'] = np.log1p(data_t['loading'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict measurement_17 & fill null column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose some higher correlation to predict measurement_17\n",
    "\n",
    "at_mots = 4 #(previous: 5 -> worse)\n",
    "code_measure = {}\n",
    "for code in data_t.product_code.unique():\n",
    "    correlation = {}\n",
    "    for col in list(featType_float): #calculate correlation\n",
    "        data_code = data_t[data_t.product_code==code]\n",
    "        value = data_code[:len(data_code)][col].corr(data_code['measurement_17'])\n",
    "        correlation[col]= np.abs(value)\n",
    "\n",
    "    # sort the correlation\n",
    "    sort_corr = np.array(sorted(correlation.items(), key=lambda x:x[1], reverse=True))\n",
    "    top_f = sort_corr[1:at_mots+1]\n",
    "    corr_feature = [feat for feat, val in top_f if float(val) > 0.1]\n",
    "    code_measure[code] = corr_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_t.copy()\n",
    "feature = [ f for f in data.columns if f=='loading' or f.startswith('measurement') ]\n",
    "\n",
    "for code in data.product_code.unique():\n",
    "    tmp = data[data.product_code==code]\n",
    "    measurement = code_measure[code]\n",
    "\n",
    "    # drop the row if it has any null values\n",
    "    tmp_train = tmp[measurement+['measurement_17']].dropna(how='any')\n",
    "    \n",
    "    # test -> only measurement_17 is null values\n",
    "    tmp_test = tmp[(tmp[measurement].isnull().sum(axis=1)==0)&(tmp['measurement_17'].isnull())]\n",
    "\n",
    "    #print(f\"code {code} : {len(tmp_test)} null values of measurement_17\")\n",
    "    \n",
    "    # use HuberRegressor to predit the column of 'measurement_17'\n",
    "    hr_model = HuberRegressor()\n",
    "    hr_model.fit(tmp_train[measurement], tmp_train['measurement_17'])\n",
    "\n",
    "    # fill those columns of 'measurement_17' is null\n",
    "    hr_pred = hr_model.predict(tmp_test[measurement])\n",
    "    index = (data.product_code==code) & (data[measurement].isnull().sum(axis=1)==0) & (data['measurement_17'].isnull())\n",
    "    data.loc[index, 'measurement_17'] = hr_pred\n",
    "\n",
    "    # fill the index who has any null value\n",
    "    knn_model = KNNImputer(n_neighbors=5)\n",
    "    #print(f\"-- KNN imputing code {code}...\")\n",
    "    knn_pred = knn_model.fit_transform(data.loc[data.product_code==code, feature])\n",
    "    data.loc[data.product_code==code, feature] = knn_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data has non null value of every column\n",
    "assert (data[feature].isnull().sum(axis=1).isnull().sum()) == 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spilt Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler_model(train_data, val_data, test_data, feature):\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # np.array\n",
    "    sc_train = scaler.fit_transform(train_data[feature])\n",
    "    sc_val = scaler.transform(val_data[feature])\n",
    "    sc_test = scaler.transform(test_data[feature])\n",
    "    \n",
    "    # dataframe\n",
    "    tmp_train, tmp_val, tmp_test = train_data.copy(), val_data.copy(), test_data.copy()\n",
    "    \n",
    "    tmp_train[feature] = sc_train\n",
    "    tmp_val[feature] = sc_val\n",
    "    tmp_test[feature] = sc_test\n",
    "    \n",
    "    return tmp_train, tmp_val, tmp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: (26570, 28)\n",
      "test data: (20775, 28)\n"
     ]
    }
   ],
   "source": [
    "train_data = data[:train_df.shape[0]]\n",
    "test_data = data[train_df.shape[0]:]\n",
    "\n",
    "assert train_data.shape[0] + test_data.shape[0] == data.shape[0]\n",
    "print(f'train data: {train_data.shape}')\n",
    "print(f'test data: {test_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = train_data.drop(['failure'], axis=1)\n",
    "Yt = train_data['failure'].astype(int)\n",
    "test = test_data.drop(['failure'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_feature = [['loading', 'measurement_17', 'm3_missing', 'm5_missing', 'measurement_1', 'measurement_2'],\n",
    "                 ['loading', 'measurement_17', 'measurement_1', 'measurement_2'],\n",
    "                 ['loading', 'measurement_17', 'm3_missing', 'm5_missing', 'measurement_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1: features['loading', 'measurement_17', 'm3_missing', 'm5_missing', 'measurement_1', 'measurement_2']\n",
      "#2: features['loading', 'measurement_17', 'measurement_1', 'measurement_2']\n",
      "#3: features['loading', 'measurement_17', 'm3_missing', 'm5_missing', 'measurement_2']\n"
     ]
    }
   ],
   "source": [
    "for idx, (feature, model_list) in enumerate(zip(round_feature, models)):\n",
    "    lr_test = np.zeros(len(test))\n",
    "    tmp_model = []\n",
    "    print(f'#{idx+1}: features{feature}')\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    for fold_idx, ((train_idx, val_idx), model) in enumerate(zip(kf.split(Xt, Yt), model_list)): \n",
    "        x_train, x_val = Xt.iloc[train_idx], Xt.iloc[val_idx]\n",
    "        y_train, y_val = Yt.iloc[train_idx], Yt.iloc[val_idx]\n",
    "        \n",
    "        x_test = test.copy()\n",
    "        \n",
    "        x_train, x_val, x_test = scaler_model(x_train, x_val, x_test, feature)\n",
    "        \n",
    "        lr_test += model.predict_proba(x_test[feature])[:, 1] / 5\n",
    "    submission_df[f'lr{idx}'] = lr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>failure</th>\n",
       "      <th>lr0</th>\n",
       "      <th>lr1</th>\n",
       "      <th>lr2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212382</td>\n",
       "      <td>0.212388</td>\n",
       "      <td>0.212396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.211852</td>\n",
       "      <td>0.211857</td>\n",
       "      <td>0.211847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212110</td>\n",
       "      <td>0.212116</td>\n",
       "      <td>0.212179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212225</td>\n",
       "      <td>0.212231</td>\n",
       "      <td>0.212276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214334</td>\n",
       "      <td>0.214340</td>\n",
       "      <td>0.214478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  failure       lr0       lr1       lr2\n",
       "0  26570      0.0  0.212382  0.212388  0.212396\n",
       "1  26571      0.0  0.211852  0.211857  0.211847\n",
       "2  26572      0.0  0.212110  0.212116  0.212179\n",
       "3  26573      0.0  0.212225  0.212231  0.212276\n",
       "4  26574      0.0  0.214334  0.214340  0.214478"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>failure</th>\n",
       "      <th>lr0</th>\n",
       "      <th>lr1</th>\n",
       "      <th>lr2</th>\n",
       "      <th>rank0</th>\n",
       "      <th>rank1</th>\n",
       "      <th>rank2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26570</td>\n",
       "      <td>8708.25</td>\n",
       "      <td>0.212382</td>\n",
       "      <td>0.212388</td>\n",
       "      <td>0.212396</td>\n",
       "      <td>8717.0</td>\n",
       "      <td>8716.0</td>\n",
       "      <td>8689.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26571</td>\n",
       "      <td>4665.50</td>\n",
       "      <td>0.211852</td>\n",
       "      <td>0.211857</td>\n",
       "      <td>0.211847</td>\n",
       "      <td>4718.0</td>\n",
       "      <td>4682.0</td>\n",
       "      <td>4585.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26572</td>\n",
       "      <td>6662.00</td>\n",
       "      <td>0.212110</td>\n",
       "      <td>0.212116</td>\n",
       "      <td>0.212179</td>\n",
       "      <td>6531.0</td>\n",
       "      <td>6511.0</td>\n",
       "      <td>6991.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26573</td>\n",
       "      <td>7515.05</td>\n",
       "      <td>0.212225</td>\n",
       "      <td>0.212231</td>\n",
       "      <td>0.212276</td>\n",
       "      <td>7435.0</td>\n",
       "      <td>7422.0</td>\n",
       "      <td>7717.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26574</td>\n",
       "      <td>20102.85</td>\n",
       "      <td>0.214334</td>\n",
       "      <td>0.214340</td>\n",
       "      <td>0.214478</td>\n",
       "      <td>20021.0</td>\n",
       "      <td>20086.0</td>\n",
       "      <td>20218.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   failure       lr0       lr1       lr2    rank0    rank1    rank2\n",
       "0  26570   8708.25  0.212382  0.212388  0.212396   8717.0   8716.0   8689.0\n",
       "1  26571   4665.50  0.211852  0.211857  0.211847   4718.0   4682.0   4585.0\n",
       "2  26572   6662.00  0.212110  0.212116  0.212179   6531.0   6511.0   6991.0\n",
       "3  26573   7515.05  0.212225  0.212231  0.212276   7435.0   7422.0   7717.0\n",
       "4  26574  20102.85  0.214334  0.214340  0.214478  20021.0  20086.0  20218.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df['rank0'] = rankdata(submission_df['lr0'])\n",
    "submission_df['rank1'] = rankdata(submission_df['lr1'])\n",
    "submission_df['rank2'] = rankdata(submission_df['lr2'])\n",
    "submission_df['failure'] = submission_df['rank0']*(0.35) + \\\n",
    "                           submission_df['rank1']*0.35 + \\\n",
    "                           submission_df['rank2']*0.3\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df[['id', 'failure']].to_csv('109550006_sub.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "acab0017710a975851146bf2aed2c4a6e826b51d438f20e36c6459ad5c57ec6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
