{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression, HuberRegressor\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from scipy.stats import rankdata\n",
    "import itertools\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (26570, 26), test (20775, 25)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "submission_df = pd.read_csv('sample_submission.csv')\n",
    "print(f'train {train_df.shape}, test {test_df.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['loading', 'measurement_3', 'measurement_4', 'measurement_5',\n",
      "       'measurement_6', 'measurement_7', 'measurement_8', 'measurement_9',\n",
      "       'measurement_10', 'measurement_11', 'measurement_12', 'measurement_13',\n",
      "       'measurement_14', 'measurement_15', 'measurement_16', 'measurement_17'],\n",
      "      dtype='object')\n",
      "Index(['id', 'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1',\n",
      "       'measurement_2', 'failure'],\n",
      "      dtype='object')\n",
      "Index(['product_code', 'attribute_0', 'attribute_1'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "total_feature = train_df.columns\n",
    "featType_float = train_df.select_dtypes(float).columns\n",
    "featType_int = train_df.select_dtypes(int).columns\n",
    "featType_object = train_df.select_dtypes(object).columns\n",
    "\n",
    "print(featType_float)\n",
    "print(featType_int)\n",
    "print(featType_object)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode: attribute0 & 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "train_df_encode = train_df.copy()\n",
    "test_df_encode = test_df.copy()\n",
    "train_size = train_df.shape[0]\n",
    "\n",
    "encode_object = featType_object.drop(['product_code'])\n",
    "for column in encode_object:\n",
    "        merge_data = pd.concat([train_df[column], test_df[column]])\n",
    "        tmp_encode = label_encoder.fit_transform(merge_data)\n",
    "        train_df_encode[column] = tmp_encode[:train_size]\n",
    "        test_df_encode[column] = tmp_encode[train_size:]\n",
    "        \n",
    "train_df = train_df_encode\n",
    "test_df = test_df_encode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kaggle discussion -> m3_missing & m5_missing are important features\n",
    "data_t = pd.concat([train_df, test_df])\n",
    "data_t['m3_missing'] = data_t['measurement_3'].isnull().astype(np.int8)\n",
    "data_t['m5_missing'] = data_t['measurement_5'].isnull().astype(np.int8)\n",
    "\n",
    "# from kaggle discussion -> suggest to log(loading)\n",
    "data_t['loading'] = np.log1p(data_t['loading'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlation: failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['loading', '0.1272022939661035'],\n",
       "       ['measurement_17', '0.033905002567120944'],\n",
       "       ['attribute_3', '0.01922213433101689'],\n",
       "       ['measurement_5', '0.018078821477476657'],\n",
       "       ['measurement_8', '0.01711945861678688'],\n",
       "       ['measurement_7', '0.01678667610884866'],\n",
       "       ['m5_missing', '0.01651857999116315'],\n",
       "       ['measurement_2', '0.015807565750564224'],\n",
       "       ['m3_missing', '0.015477595735098788'],\n",
       "       ['attribute_0', '0.014829601287774169'],\n",
       "       ['measurement_6', '0.014791019365985439'],\n",
       "       ['attribute_1', '0.011999161647528154'],\n",
       "       ['measurement_1', '0.01080998860865806'],\n",
       "       ['measurement_4', '0.010488110572352235'],\n",
       "       ['measurement_0', '0.009645933201494657'],\n",
       "       ['attribute_2', '0.006336975021853562'],\n",
       "       ['measurement_14', '0.0062108925877654595'],\n",
       "       ['measurement_11', '0.0048014263775955105'],\n",
       "       ['measurement_12', '0.004398103485910207'],\n",
       "       ['measurement_9', '0.0035874245134301787'],\n",
       "       ['measurement_3', '0.003576828371350914'],\n",
       "       ['measurement_15', '0.003544022781733942'],\n",
       "       ['measurement_16', '0.002236967455623256'],\n",
       "       ['measurement_13', '0.0018312953233656038'],\n",
       "       ['measurement_10', '0.0015154288511520595']], dtype='<U32')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_failure={}\n",
    "data_feat = data_t.drop(['id', 'product_code', 'failure'], axis=1).columns\n",
    "for col in list(data_feat):\n",
    "    corr = data_t[:len(train_df)][col].corr(train_df['failure'])\n",
    "    corr_failure[col]= np.abs(corr) #corr\n",
    "\n",
    "sort_corr_failure = np.array(sorted(corr_failure.items(), key=lambda x:x[1], reverse=True))\n",
    "corr_fail_feature = list(sort_corr_failure[:,0])\n",
    "sort_corr_failure\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict measurement_17 & fill null column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code A:\n",
      "['measurement_8', 'measurement_5', 'measurement_6', 'measurement_7']\n",
      "code B:\n",
      "['measurement_7', 'measurement_4', 'measurement_5', 'measurement_9']\n",
      "code C:\n",
      "['measurement_8', 'measurement_5', 'measurement_7', 'measurement_9']\n",
      "code D:\n",
      "['measurement_6', 'measurement_5', 'measurement_8', 'measurement_7']\n",
      "code E:\n",
      "['measurement_6', 'measurement_8', 'measurement_5', 'measurement_4']\n",
      "code F:\n",
      "['measurement_6', 'measurement_4', 'measurement_7', 'measurement_5']\n",
      "code G:\n",
      "['measurement_6', 'measurement_4', 'measurement_8', 'measurement_9']\n",
      "code H:\n",
      "['measurement_5', 'measurement_9', 'measurement_4', 'measurement_8']\n",
      "code I:\n",
      "['measurement_8', 'measurement_3', 'measurement_7', 'measurement_9']\n"
     ]
    }
   ],
   "source": [
    "# choose some higher correlation to predict measurement_17\n",
    "\n",
    "at_mots = 4 #(previous: 5 -> worse)\n",
    "code_measure = {}\n",
    "for code in data_t.product_code.unique():\n",
    "    correlation = {}\n",
    "    for col in list(featType_float): #calculate correlation\n",
    "        data_code = data_t[data_t.product_code==code]\n",
    "        value = data_code[:len(data_code)][col].corr(data_code['measurement_17'])\n",
    "        correlation[col]= np.abs(value)\n",
    "\n",
    "    # sort the correlation\n",
    "    sort_corr = np.array(sorted(correlation.items(), key=lambda x:x[1], reverse=True))\n",
    "    top_f = sort_corr[1:at_mots+1]\n",
    "    corr_feature = [feat for feat, val in top_f if float(val) > 0.1]\n",
    "    code_measure[code] = corr_feature\n",
    "    print(f'code {code}:\\n{corr_feature}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code A : 374 null values of measurement_17\n",
      "-- KNN imputing code A...\n",
      "code B : 397 null values of measurement_17\n",
      "-- KNN imputing code B...\n",
      "code C : 391 null values of measurement_17\n",
      "-- KNN imputing code C...\n",
      "code D : 398 null values of measurement_17\n",
      "-- KNN imputing code D...\n",
      "code E : 429 null values of measurement_17\n",
      "-- KNN imputing code E...\n",
      "code F : 420 null values of measurement_17\n",
      "-- KNN imputing code F...\n",
      "code G : 373 null values of measurement_17\n",
      "-- KNN imputing code G...\n",
      "code H : 378 null values of measurement_17\n",
      "-- KNN imputing code H...\n",
      "code I : 358 null values of measurement_17\n",
      "-- KNN imputing code I...\n"
     ]
    }
   ],
   "source": [
    "data = data_t.copy()\n",
    "feature = [ f for f in data.columns if f=='loading' or f.startswith('measurement') ]\n",
    "\n",
    "for code in data.product_code.unique():\n",
    "    tmp = data[data.product_code==code]\n",
    "    measurement = code_measure[code]\n",
    "\n",
    "    # drop the row if it has any null values\n",
    "    tmp_train = tmp[measurement+['measurement_17']].dropna(how='any')\n",
    "    \n",
    "    # test -> only measurement_17 is null values\n",
    "    tmp_test = tmp[(tmp[measurement].isnull().sum(axis=1)==0)&(tmp['measurement_17'].isnull())]\n",
    "\n",
    "    print(f\"code {code} : {len(tmp_test)} null values of measurement_17\")\n",
    "    \n",
    "    # use HuberRegressor to predit the column of 'measurement_17'\n",
    "    hr_model = HuberRegressor()\n",
    "    hr_model.fit(tmp_train[measurement], tmp_train['measurement_17'])\n",
    "\n",
    "    # fill those columns of 'measurement_17' is null\n",
    "    hr_pred = hr_model.predict(tmp_test[measurement])\n",
    "    index = (data.product_code==code) & (data[measurement].isnull().sum(axis=1)==0) & (data['measurement_17'].isnull())\n",
    "    data.loc[index, 'measurement_17'] = hr_pred\n",
    "\n",
    "    # fill the index who has any null value\n",
    "    knn_model = KNNImputer(n_neighbors=5)\n",
    "    print(f\"-- KNN imputing code {code}...\")\n",
    "    knn_pred = knn_model.fit_transform(data.loc[data.product_code==code, feature])\n",
    "    data.loc[data.product_code==code, feature] = knn_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data has non null value of every column\n",
    "assert (data[feature].isnull().sum(axis=1).isnull().sum()) == 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spilt Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler_model(train_data, val_data, test_data, feature):\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # np.array\n",
    "    sc_train = scaler.fit_transform(train_data[feature])\n",
    "    sc_val = scaler.transform(val_data[feature])\n",
    "    sc_test = scaler.transform(test_data[feature])\n",
    "    \n",
    "    # dataframe\n",
    "    tmp_train, tmp_val, tmp_test = train_data.copy(), val_data.copy(), test_data.copy()\n",
    "    \n",
    "    tmp_train[feature] = sc_train\n",
    "    tmp_val[feature] = sc_val\n",
    "    tmp_test[feature] = sc_test\n",
    "    \n",
    "    return tmp_train, tmp_val, tmp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: (26570, 28)\n",
      "test data: (20775, 28)\n"
     ]
    }
   ],
   "source": [
    "train_data = data[:train_df.shape[0]]\n",
    "test_data = data[train_df.shape[0]:]\n",
    "\n",
    "assert train_data.shape[0] + test_data.shape[0] == data.shape[0]\n",
    "print(f'train data: {train_data.shape}')\n",
    "print(f'test data: {test_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = train_data.drop(['failure'], axis=1)\n",
    "Yt = train_data['failure'].astype(int)\n",
    "test = test_data.drop(['failure'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important feature\n",
    "round_feature = [['loading', 'measurement_17', 'm3_missing', 'm5_missing', 'measurement_1', 'measurement_2'],\n",
    "                 ['loading', 'measurement_17', 'measurement_1', 'measurement_2'],\n",
    "                 ['loading', 'measurement_17', 'm3_missing', 'm5_missing', 'measurement_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0: features['loading', 'measurement_17', 'm3_missing', 'm5_missing', 'measurement_1', 'measurement_2']\n",
      "\tAverage auc = 0.59119, Average acc = 0.78739\n",
      "#1: features['loading', 'measurement_17', 'measurement_1', 'measurement_2']\n",
      "\tAverage auc = 0.59036, Average acc = 0.78739\n",
      "#2: features['loading', 'measurement_17', 'm3_missing', 'm5_missing', 'measurement_2']\n",
      "\tAverage auc = 0.59097, Average acc = 0.78739\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "C_tmp = [0.0001, 0.00005, 0.00001, 0.000005, 0.000001]\n",
    "\n",
    "for idx, feature in enumerate(round_feature):\n",
    "    lr_test = np.zeros(len(test))\n",
    "    lr_auc, lr_acc = 0, 0\n",
    "    tmp_model = []\n",
    "    print(f'#{idx}: features{feature}')\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(kf.split(Xt, Yt)):\n",
    "        #print(\"  Fold:\", fold_idx+1)\n",
    "        x_train, x_val = Xt.iloc[train_idx], Xt.iloc[val_idx]\n",
    "        y_train, y_val = Yt.iloc[train_idx], Yt.iloc[val_idx]\n",
    "        x_test = test.copy()\n",
    "        \n",
    "        x_train, x_val, x_test = scaler_model(x_train, x_val, x_test, feature)\n",
    "        \n",
    "        lr_model = LogisticRegression(max_iter=1000,\n",
    "                                      C=0.000005,#0.000005,\n",
    "                                      penalty='l2',\n",
    "                                      solver='newton-cg')\n",
    "        lr_model.fit(x_train[feature], y_train)\n",
    "\n",
    "        val_preds = lr_model.predict_proba(x_val[feature])[:, 1]\n",
    "        lr_auc += roc_auc_score(y_val, val_preds) / 5\n",
    "        y_preds = lr_model.predict(x_val[feature])\n",
    "        lr_acc += accuracy_score(y_val, y_preds) / 5\n",
    "        lr_test += lr_model.predict_proba(x_test[feature])[:, 1] / 5\n",
    "        tmp_model.append(lr_model)\n",
    "    models.append(tmp_model)\n",
    "    print(f\"\\tAverage auc = {np.round(lr_auc, 5)}, Average acc = {np.round(lr_acc, 5)}\")\n",
    "    submission_df[f'lr{idx}'] = lr_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LogisticRegression(C=5e-06, max_iter=1000, solver='newton-cg'), LogisticRegression(C=5e-06, max_iter=1000, solver='newton-cg'), LogisticRegression(C=5e-06, max_iter=1000, solver='newton-cg'), LogisticRegression(C=5e-06, max_iter=1000, solver='newton-cg'), LogisticRegression(C=5e-06, max_iter=1000, solver='newton-cg')]\n",
      "[LogisticRegression(C=5e-06, max_iter=1000, solver='newton-cg'), LogisticRegression(C=5e-06, max_iter=1000, solver='newton-cg'), LogisticRegression(C=5e-06, max_iter=1000, solver='newton-cg'), LogisticRegression(C=5e-06, max_iter=1000, solver='newton-cg'), LogisticRegression(C=5e-06, max_iter=1000, solver='newton-cg')]\n",
      "[LogisticRegression(C=5e-06, max_iter=1000, solver='newton-cg'), LogisticRegression(C=5e-06, max_iter=1000, solver='newton-cg'), LogisticRegression(C=5e-06, max_iter=1000, solver='newton-cg'), LogisticRegression(C=5e-06, max_iter=1000, solver='newton-cg'), LogisticRegression(C=5e-06, max_iter=1000, solver='newton-cg')]\n"
     ]
    }
   ],
   "source": [
    "with open(\"models.pckl\", \"wb\") as f:\n",
    "    for list_model in models:\n",
    "        print(list_model)\n",
    "        for model in list_model:\n",
    "            pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_df['rank0'] = rankdata(submission_df['lr0'])\n",
    "# submission_df['rank1'] = rankdata(submission_df['lr1'])\n",
    "# submission_df['rank2'] = rankdata(submission_df['lr2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_df['failure'] = submission_df['rank0']*(0.3) + \\\n",
    "#                          submission_df['rank1']*0.3 + \\\n",
    "#                          submission_df['rank2']*0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_df[['id', 'failure']].to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "acab0017710a975851146bf2aed2c4a6e826b51d438f20e36c6459ad5c57ec6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
